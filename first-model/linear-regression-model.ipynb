{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "POKmsP7KE8ZE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "bias = 0.3\n",
        "weight = 0.7\n",
        "\n",
        "start = 0\n",
        "end = 1\n",
        "step = 0.02\n",
        "X = torch.arange(start, end, step).unsqueeze(dim=1)\n",
        "y = weight*X + bias\n",
        "\n",
        "# we'll get the 80% for training \n",
        "# we'll get the rest 20% for testing \n",
        "train_split = int(0.8 * len(X))\n",
        "X_train = X[:train_split]\n",
        "y_train = y[:train_split]\n",
        "\n",
        "X_test = X[train_split:]\n",
        "y_test = y[train_split:]\n",
        "\n",
        "#len(X_train), len(y_train), len(X_test), len(y_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's visualiaze our data"
      ],
      "metadata": {
        "id": "4rGjsemxPQMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_data_and_predictions(train_data=X_train,\n",
        "                              train_labels=y_train,\n",
        "                              test_data=X_test,\n",
        "                              test_labels=y_test,\n",
        "                              predictions=None):\n",
        "  \n",
        "  plt.figure(figsize=(10, 7))\n",
        "  plt.scatter(train_data, train_labels, c=\"black\", s=4, label=\"Training data\")\n",
        "  plt.scatter(test_data, test_labels, c=\"g\", s=4, label=\"Testing data\")\n",
        "  if(predictions is not None):\n",
        "    plt.scatter(test_data, predictions, c=\"r\", s=4, label=\"Predictions\")\n",
        "  \n",
        "  plt.legend(prop={\n",
        "      \"size\": 14\n",
        "  })\n",
        "\n",
        "plot_data_and_predictions()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "vb-u9F25PREG",
        "outputId": "e4c70ddc-d81d-4332-d27e-2089d1eb71c5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "My first ever Machine Learning model"
      ],
      "metadata": {
        "id": "t0SNUC4sSMXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearRegressionModel(nn.Module):\n",
        "  # almost everything in PyTorch inherhits from nn.Module, so we have to let's say 'include' it\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.weights = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
        "    self.bias = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
        "\n",
        "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "    return self.weights*x + self.bias"
      ],
      "metadata": {
        "id": "xBSTK14dSQ7j"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "my_model = LinearRegressionModel()\n",
        "#Let's check the parameters\n",
        "#list(my_model.parameters())\n",
        "\n",
        "my_model.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dr8cfbFjS11v",
        "outputId": "e359495c-e8d5-4a85-f08c-8e1d197c3ad5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weights', tensor([0.3367])), ('bias', tensor([0.1288]))])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.inference_mode():\n",
        "  y_preds = my_model(X_test)\n",
        "y_preds\n",
        "\n",
        "plot_data_and_predictions(predictions=y_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "JZJlIgBcdBMX",
        "outputId": "e0151354-65f6-4c9a-9305-b04b05faf79a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup a loss function"
      ],
      "metadata": {
        "id": "-SXtQmvijs7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.L1Loss()"
      ],
      "metadata": {
        "id": "d0GP49ZdjwTo"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup an optimizer (Stochastic Gradient Descent) with learning rate to be 0.01\n",
        "\n",
        "(the larger the learing rate the more dangerous it is)\n",
        "\n",
        "(the smaller the learing rate the safer but slower it is)\n",
        "\n",
        "Learning rate has to be neither too large nor too small."
      ],
      "metadata": {
        "id": "82UKUMAYj1tj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(params=my_model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "c2Dsgv5-j3ra"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building a training loop (and a testing loop)\n",
        "\n",
        "Because we set the learning rate to 0.01 it means that we need more iterations than if you did selected lr=0.1"
      ],
      "metadata": {
        "id": "7FKhasUUlIpU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 700\n",
        "for epoch in range(epochs):\n",
        "  my_model.train()\n",
        "\n",
        "  y_pred = my_model(X_train)\n",
        "  loss = loss_fn(y_pred, y_train)\n",
        "  print(f\"Loss : {loss}  ==  epoch={epoch}\")\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  print(my_model.state_dict())\n",
        "  #my_model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIl7TIPWlMvG",
        "outputId": "4b7964e3-35f1-4956-ea9d-053792f43e2f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss : 0.31288138031959534  ==  epoch=0\n",
            "OrderedDict([('weights', tensor([0.3406])), ('bias', tensor([0.1388]))])\n",
            "Loss : 0.3013603389263153  ==  epoch=1\n",
            "OrderedDict([('weights', tensor([0.3445])), ('bias', tensor([0.1488]))])\n",
            "Loss : 0.28983935713768005  ==  epoch=2\n",
            "OrderedDict([('weights', tensor([0.3484])), ('bias', tensor([0.1588]))])\n",
            "Loss : 0.2783183455467224  ==  epoch=3\n",
            "OrderedDict([('weights', tensor([0.3523])), ('bias', tensor([0.1688]))])\n",
            "Loss : 0.26679736375808716  ==  epoch=4\n",
            "OrderedDict([('weights', tensor([0.3562])), ('bias', tensor([0.1788]))])\n",
            "Loss : 0.2552763521671295  ==  epoch=5\n",
            "OrderedDict([('weights', tensor([0.3601])), ('bias', tensor([0.1888]))])\n",
            "Loss : 0.24375534057617188  ==  epoch=6\n",
            "OrderedDict([('weights', tensor([0.3640])), ('bias', tensor([0.1988]))])\n",
            "Loss : 0.23223432898521423  ==  epoch=7\n",
            "OrderedDict([('weights', tensor([0.3679])), ('bias', tensor([0.2088]))])\n",
            "Loss : 0.22071333229541779  ==  epoch=8\n",
            "OrderedDict([('weights', tensor([0.3718])), ('bias', tensor([0.2188]))])\n",
            "Loss : 0.20919232070446014  ==  epoch=9\n",
            "OrderedDict([('weights', tensor([0.3757])), ('bias', tensor([0.2288]))])\n",
            "Loss : 0.1976713240146637  ==  epoch=10\n",
            "OrderedDict([('weights', tensor([0.3796])), ('bias', tensor([0.2388]))])\n",
            "Loss : 0.18615034222602844  ==  epoch=11\n",
            "OrderedDict([('weights', tensor([0.3835])), ('bias', tensor([0.2488]))])\n",
            "Loss : 0.1746293306350708  ==  epoch=12\n",
            "OrderedDict([('weights', tensor([0.3874])), ('bias', tensor([0.2588]))])\n",
            "Loss : 0.16310831904411316  ==  epoch=13\n",
            "OrderedDict([('weights', tensor([0.3913])), ('bias', tensor([0.2688]))])\n",
            "Loss : 0.1515873372554779  ==  epoch=14\n",
            "OrderedDict([('weights', tensor([0.3952])), ('bias', tensor([0.2788]))])\n",
            "Loss : 0.14006635546684265  ==  epoch=15\n",
            "OrderedDict([('weights', tensor([0.3991])), ('bias', tensor([0.2888]))])\n",
            "Loss : 0.1285453587770462  ==  epoch=16\n",
            "OrderedDict([('weights', tensor([0.4030])), ('bias', tensor([0.2988]))])\n",
            "Loss : 0.11702437698841095  ==  epoch=17\n",
            "OrderedDict([('weights', tensor([0.4069])), ('bias', tensor([0.3088]))])\n",
            "Loss : 0.1060912236571312  ==  epoch=18\n",
            "OrderedDict([('weights', tensor([0.4108])), ('bias', tensor([0.3178]))])\n",
            "Loss : 0.09681284427642822  ==  epoch=19\n",
            "OrderedDict([('weights', tensor([0.4146])), ('bias', tensor([0.3258]))])\n",
            "Loss : 0.08908725529909134  ==  epoch=20\n",
            "OrderedDict([('weights', tensor([0.4184])), ('bias', tensor([0.3333]))])\n",
            "Loss : 0.08227583020925522  ==  epoch=21\n",
            "OrderedDict([('weights', tensor([0.4222])), ('bias', tensor([0.3403]))])\n",
            "Loss : 0.07638873159885406  ==  epoch=22\n",
            "OrderedDict([('weights', tensor([0.4258])), ('bias', tensor([0.3463]))])\n",
            "Loss : 0.07160007208585739  ==  epoch=23\n",
            "OrderedDict([('weights', tensor([0.4293])), ('bias', tensor([0.3518]))])\n",
            "Loss : 0.06747635453939438  ==  epoch=24\n",
            "OrderedDict([('weights', tensor([0.4328])), ('bias', tensor([0.3568]))])\n",
            "Loss : 0.06395438313484192  ==  epoch=25\n",
            "OrderedDict([('weights', tensor([0.4361])), ('bias', tensor([0.3613]))])\n",
            "Loss : 0.06097004935145378  ==  epoch=26\n",
            "OrderedDict([('weights', tensor([0.4394])), ('bias', tensor([0.3653]))])\n",
            "Loss : 0.05845819041132927  ==  epoch=27\n",
            "OrderedDict([('weights', tensor([0.4425])), ('bias', tensor([0.3688]))])\n",
            "Loss : 0.05635259300470352  ==  epoch=28\n",
            "OrderedDict([('weights', tensor([0.4455])), ('bias', tensor([0.3718]))])\n",
            "Loss : 0.0545857772231102  ==  epoch=29\n",
            "OrderedDict([('weights', tensor([0.4483])), ('bias', tensor([0.3743]))])\n",
            "Loss : 0.053148526698350906  ==  epoch=30\n",
            "OrderedDict([('weights', tensor([0.4512])), ('bias', tensor([0.3768]))])\n",
            "Loss : 0.05181945487856865  ==  epoch=31\n",
            "OrderedDict([('weights', tensor([0.4539])), ('bias', tensor([0.3788]))])\n",
            "Loss : 0.05069301277399063  ==  epoch=32\n",
            "OrderedDict([('weights', tensor([0.4564])), ('bias', tensor([0.3803]))])\n",
            "Loss : 0.0498228520154953  ==  epoch=33\n",
            "OrderedDict([('weights', tensor([0.4590])), ('bias', tensor([0.3818]))])\n",
            "Loss : 0.04895269125699997  ==  epoch=34\n",
            "OrderedDict([('weights', tensor([0.4615])), ('bias', tensor([0.3833]))])\n",
            "Loss : 0.04819351062178612  ==  epoch=35\n",
            "OrderedDict([('weights', tensor([0.4639])), ('bias', tensor([0.3843]))])\n",
            "Loss : 0.047531817108392715  ==  epoch=36\n",
            "OrderedDict([('weights', tensor([0.4662])), ('bias', tensor([0.3853]))])\n",
            "Loss : 0.04692792519927025  ==  epoch=37\n",
            "OrderedDict([('weights', tensor([0.4684])), ('bias', tensor([0.3858]))])\n",
            "Loss : 0.04642331600189209  ==  epoch=38\n",
            "OrderedDict([('weights', tensor([0.4706])), ('bias', tensor([0.3863]))])\n",
            "Loss : 0.04591871052980423  ==  epoch=39\n",
            "OrderedDict([('weights', tensor([0.4728])), ('bias', tensor([0.3868]))])\n",
            "Loss : 0.04543796554207802  ==  epoch=40\n",
            "OrderedDict([('weights', tensor([0.4748])), ('bias', tensor([0.3868]))])\n",
            "Loss : 0.04503796249628067  ==  epoch=41\n",
            "OrderedDict([('weights', tensor([0.4768])), ('bias', tensor([0.3868]))])\n",
            "Loss : 0.04463795945048332  ==  epoch=42\n",
            "OrderedDict([('weights', tensor([0.4788])), ('bias', tensor([0.3868]))])\n",
            "Loss : 0.04423796385526657  ==  epoch=43\n",
            "OrderedDict([('weights', tensor([0.4808])), ('bias', tensor([0.3868]))])\n",
            "Loss : 0.04383796453475952  ==  epoch=44\n",
            "OrderedDict([('weights', tensor([0.4828])), ('bias', tensor([0.3868]))])\n",
            "Loss : 0.04343796148896217  ==  epoch=45\n",
            "OrderedDict([('weights', tensor([0.4848])), ('bias', tensor([0.3868]))])\n",
            "Loss : 0.043074630200862885  ==  epoch=46\n",
            "OrderedDict([('weights', tensor([0.4866])), ('bias', tensor([0.3863]))])\n",
            "Loss : 0.04272563382983208  ==  epoch=47\n",
            "OrderedDict([('weights', tensor([0.4884])), ('bias', tensor([0.3858]))])\n",
            "Loss : 0.04237663000822067  ==  epoch=48\n",
            "OrderedDict([('weights', tensor([0.4902])), ('bias', tensor([0.3853]))])\n",
            "Loss : 0.04202762991189957  ==  epoch=49\n",
            "OrderedDict([('weights', tensor([0.4920])), ('bias', tensor([0.3848]))])\n",
            "Loss : 0.04167863354086876  ==  epoch=50\n",
            "OrderedDict([('weights', tensor([0.4938])), ('bias', tensor([0.3843]))])\n",
            "Loss : 0.04132963344454765  ==  epoch=51\n",
            "OrderedDict([('weights', tensor([0.4956])), ('bias', tensor([0.3838]))])\n",
            "Loss : 0.04098063334822655  ==  epoch=52\n",
            "OrderedDict([('weights', tensor([0.4974])), ('bias', tensor([0.3833]))])\n",
            "Loss : 0.04063162952661514  ==  epoch=53\n",
            "OrderedDict([('weights', tensor([0.4992])), ('bias', tensor([0.3828]))])\n",
            "Loss : 0.040282636880874634  ==  epoch=54\n",
            "OrderedDict([('weights', tensor([0.5010])), ('bias', tensor([0.3823]))])\n",
            "Loss : 0.039933640509843826  ==  epoch=55\n",
            "OrderedDict([('weights', tensor([0.5028])), ('bias', tensor([0.3818]))])\n",
            "Loss : 0.03958464413881302  ==  epoch=56\n",
            "OrderedDict([('weights', tensor([0.5046])), ('bias', tensor([0.3813]))])\n",
            "Loss : 0.03923564404249191  ==  epoch=57\n",
            "OrderedDict([('weights', tensor([0.5064])), ('bias', tensor([0.3808]))])\n",
            "Loss : 0.03888664394617081  ==  epoch=58\n",
            "OrderedDict([('weights', tensor([0.5082])), ('bias', tensor([0.3803]))])\n",
            "Loss : 0.0385376438498497  ==  epoch=59\n",
            "OrderedDict([('weights', tensor([0.5100])), ('bias', tensor([0.3798]))])\n",
            "Loss : 0.03818932920694351  ==  epoch=60\n",
            "OrderedDict([('weights', tensor([0.5116])), ('bias', tensor([0.3788]))])\n",
            "Loss : 0.03785243630409241  ==  epoch=61\n",
            "OrderedDict([('weights', tensor([0.5134])), ('bias', tensor([0.3783]))])\n",
            "Loss : 0.0375034399330616  ==  epoch=62\n",
            "OrderedDict([('weights', tensor([0.5152])), ('bias', tensor([0.3778]))])\n",
            "Loss : 0.037164121866226196  ==  epoch=63\n",
            "OrderedDict([('weights', tensor([0.5168])), ('bias', tensor([0.3768]))])\n",
            "Loss : 0.03681822493672371  ==  epoch=64\n",
            "OrderedDict([('weights', tensor([0.5186])), ('bias', tensor([0.3763]))])\n",
            "Loss : 0.03647511452436447  ==  epoch=65\n",
            "OrderedDict([('weights', tensor([0.5202])), ('bias', tensor([0.3753]))])\n",
            "Loss : 0.03613303601741791  ==  epoch=66\n",
            "OrderedDict([('weights', tensor([0.5220])), ('bias', tensor([0.3748]))])\n",
            "Loss : 0.03578609973192215  ==  epoch=67\n",
            "OrderedDict([('weights', tensor([0.5236])), ('bias', tensor([0.3738]))])\n",
            "Loss : 0.03544783592224121  ==  epoch=68\n",
            "OrderedDict([('weights', tensor([0.5254])), ('bias', tensor([0.3733]))])\n",
            "Loss : 0.035098835825920105  ==  epoch=69\n",
            "OrderedDict([('weights', tensor([0.5272])), ('bias', tensor([0.3728]))])\n",
            "Loss : 0.03476089984178543  ==  epoch=70\n",
            "OrderedDict([('weights', tensor([0.5288])), ('bias', tensor([0.3718]))])\n",
            "Loss : 0.03441363573074341  ==  epoch=71\n",
            "OrderedDict([('weights', tensor([0.5306])), ('bias', tensor([0.3713]))])\n",
            "Loss : 0.03407188132405281  ==  epoch=72\n",
            "OrderedDict([('weights', tensor([0.5322])), ('bias', tensor([0.3703]))])\n",
            "Loss : 0.03372843936085701  ==  epoch=73\n",
            "OrderedDict([('weights', tensor([0.5340])), ('bias', tensor([0.3698]))])\n",
            "Loss : 0.03338287025690079  ==  epoch=74\n",
            "OrderedDict([('weights', tensor([0.5355])), ('bias', tensor([0.3688]))])\n",
            "Loss : 0.033043231815099716  ==  epoch=75\n",
            "OrderedDict([('weights', tensor([0.5373])), ('bias', tensor([0.3683]))])\n",
            "Loss : 0.03269423171877861  ==  epoch=76\n",
            "OrderedDict([('weights', tensor([0.5391])), ('bias', tensor([0.3678]))])\n",
            "Loss : 0.032357655465602875  ==  epoch=77\n",
            "OrderedDict([('weights', tensor([0.5407])), ('bias', tensor([0.3668]))])\n",
            "Loss : 0.03200903534889221  ==  epoch=78\n",
            "OrderedDict([('weights', tensor([0.5425])), ('bias', tensor([0.3663]))])\n",
            "Loss : 0.03166864812374115  ==  epoch=79\n",
            "OrderedDict([('weights', tensor([0.5441])), ('bias', tensor([0.3653]))])\n",
            "Loss : 0.03132382780313492  ==  epoch=80\n",
            "OrderedDict([('weights', tensor([0.5459])), ('bias', tensor([0.3648]))])\n",
            "Loss : 0.030979642644524574  ==  epoch=81\n",
            "OrderedDict([('weights', tensor([0.5475])), ('bias', tensor([0.3638]))])\n",
            "Loss : 0.030638623982667923  ==  epoch=82\n",
            "OrderedDict([('weights', tensor([0.5493])), ('bias', tensor([0.3633]))])\n",
            "Loss : 0.0302906334400177  ==  epoch=83\n",
            "OrderedDict([('weights', tensor([0.5509])), ('bias', tensor([0.3623]))])\n",
            "Loss : 0.029953425750136375  ==  epoch=84\n",
            "OrderedDict([('weights', tensor([0.5527])), ('bias', tensor([0.3618]))])\n",
            "Loss : 0.02960442565381527  ==  epoch=85\n",
            "OrderedDict([('weights', tensor([0.5545])), ('bias', tensor([0.3613]))])\n",
            "Loss : 0.029265418648719788  ==  epoch=86\n",
            "OrderedDict([('weights', tensor([0.5561])), ('bias', tensor([0.3603]))])\n",
            "Loss : 0.028919223695993423  ==  epoch=87\n",
            "OrderedDict([('weights', tensor([0.5579])), ('bias', tensor([0.3598]))])\n",
            "Loss : 0.028576409444212914  ==  epoch=88\n",
            "OrderedDict([('weights', tensor([0.5595])), ('bias', tensor([0.3588]))])\n",
            "Loss : 0.028234025463461876  ==  epoch=89\n",
            "OrderedDict([('weights', tensor([0.5613])), ('bias', tensor([0.3583]))])\n",
            "Loss : 0.02788739837706089  ==  epoch=90\n",
            "OrderedDict([('weights', tensor([0.5629])), ('bias', tensor([0.3573]))])\n",
            "Loss : 0.02754882536828518  ==  epoch=91\n",
            "OrderedDict([('weights', tensor([0.5647])), ('bias', tensor([0.3568]))])\n",
            "Loss : 0.027199819684028625  ==  epoch=92\n",
            "OrderedDict([('weights', tensor([0.5665])), ('bias', tensor([0.3563]))])\n",
            "Loss : 0.026862185448408127  ==  epoch=93\n",
            "OrderedDict([('weights', tensor([0.5681])), ('bias', tensor([0.3553]))])\n",
            "Loss : 0.02651461586356163  ==  epoch=94\n",
            "OrderedDict([('weights', tensor([0.5699])), ('bias', tensor([0.3548]))])\n",
            "Loss : 0.026173178106546402  ==  epoch=95\n",
            "OrderedDict([('weights', tensor([0.5715])), ('bias', tensor([0.3538]))])\n",
            "Loss : 0.025829419493675232  ==  epoch=96\n",
            "OrderedDict([('weights', tensor([0.5733])), ('bias', tensor([0.3533]))])\n",
            "Loss : 0.02548416517674923  ==  epoch=97\n",
            "OrderedDict([('weights', tensor([0.5748])), ('bias', tensor([0.3523]))])\n",
            "Loss : 0.025144213810563087  ==  epoch=98\n",
            "OrderedDict([('weights', tensor([0.5766])), ('bias', tensor([0.3518]))])\n",
            "Loss : 0.02479521557688713  ==  epoch=99\n",
            "OrderedDict([('weights', tensor([0.5784])), ('bias', tensor([0.3513]))])\n",
            "Loss : 0.024458957836031914  ==  epoch=100\n",
            "OrderedDict([('weights', tensor([0.5800])), ('bias', tensor([0.3503]))])\n",
            "Loss : 0.024110013619065285  ==  epoch=101\n",
            "OrderedDict([('weights', tensor([0.5818])), ('bias', tensor([0.3498]))])\n",
            "Loss : 0.02376994863152504  ==  epoch=102\n",
            "OrderedDict([('weights', tensor([0.5834])), ('bias', tensor([0.3488]))])\n",
            "Loss : 0.02342480979859829  ==  epoch=103\n",
            "OrderedDict([('weights', tensor([0.5852])), ('bias', tensor([0.3483]))])\n",
            "Loss : 0.023080935701727867  ==  epoch=104\n",
            "OrderedDict([('weights', tensor([0.5868])), ('bias', tensor([0.3473]))])\n",
            "Loss : 0.022739607840776443  ==  epoch=105\n",
            "OrderedDict([('weights', tensor([0.5886])), ('bias', tensor([0.3468]))])\n",
            "Loss : 0.022391926497220993  ==  epoch=106\n",
            "OrderedDict([('weights', tensor([0.5902])), ('bias', tensor([0.3458]))])\n",
            "Loss : 0.022054409608244896  ==  epoch=107\n",
            "OrderedDict([('weights', tensor([0.5920])), ('bias', tensor([0.3453]))])\n",
            "Loss : 0.02170540764927864  ==  epoch=108\n",
            "OrderedDict([('weights', tensor([0.5938])), ('bias', tensor([0.3448]))])\n",
            "Loss : 0.021366719156503677  ==  epoch=109\n",
            "OrderedDict([('weights', tensor([0.5954])), ('bias', tensor([0.3438]))])\n",
            "Loss : 0.021020207554101944  ==  epoch=110\n",
            "OrderedDict([('weights', tensor([0.5972])), ('bias', tensor([0.3433]))])\n",
            "Loss : 0.020677709951996803  ==  epoch=111\n",
            "OrderedDict([('weights', tensor([0.5988])), ('bias', tensor([0.3423]))])\n",
            "Loss : 0.02033500373363495  ==  epoch=112\n",
            "OrderedDict([('weights', tensor([0.6006])), ('bias', tensor([0.3418]))])\n",
            "Loss : 0.01998869702219963  ==  epoch=113\n",
            "OrderedDict([('weights', tensor([0.6022])), ('bias', tensor([0.3408]))])\n",
            "Loss : 0.019649803638458252  ==  epoch=114\n",
            "OrderedDict([('weights', tensor([0.6040])), ('bias', tensor([0.3403]))])\n",
            "Loss : 0.019300809130072594  ==  epoch=115\n",
            "OrderedDict([('weights', tensor([0.6058])), ('bias', tensor([0.3398]))])\n",
            "Loss : 0.018963487818837166  ==  epoch=116\n",
            "OrderedDict([('weights', tensor([0.6074])), ('bias', tensor([0.3388]))])\n",
            "Loss : 0.01861560344696045  ==  epoch=117\n",
            "OrderedDict([('weights', tensor([0.6092])), ('bias', tensor([0.3383]))])\n",
            "Loss : 0.018274478614330292  ==  epoch=118\n",
            "OrderedDict([('weights', tensor([0.6108])), ('bias', tensor([0.3373]))])\n",
            "Loss : 0.017930403351783752  ==  epoch=119\n",
            "OrderedDict([('weights', tensor([0.6126])), ('bias', tensor([0.3368]))])\n",
            "Loss : 0.01758546568453312  ==  epoch=120\n",
            "OrderedDict([('weights', tensor([0.6141])), ('bias', tensor([0.3358]))])\n",
            "Loss : 0.017245199531316757  ==  epoch=121\n",
            "OrderedDict([('weights', tensor([0.6159])), ('bias', tensor([0.3353]))])\n",
            "Loss : 0.016896454617381096  ==  epoch=122\n",
            "OrderedDict([('weights', tensor([0.6175])), ('bias', tensor([0.3343]))])\n",
            "Loss : 0.01656000316143036  ==  epoch=123\n",
            "OrderedDict([('weights', tensor([0.6193])), ('bias', tensor([0.3338]))])\n",
            "Loss : 0.016210997477173805  ==  epoch=124\n",
            "OrderedDict([('weights', tensor([0.6211])), ('bias', tensor([0.3333]))])\n",
            "Loss : 0.01587124727666378  ==  epoch=125\n",
            "OrderedDict([('weights', tensor([0.6227])), ('bias', tensor([0.3323]))])\n",
            "Loss : 0.015525798313319683  ==  epoch=126\n",
            "OrderedDict([('weights', tensor([0.6245])), ('bias', tensor([0.3318]))])\n",
            "Loss : 0.015182236209511757  ==  epoch=127\n",
            "OrderedDict([('weights', tensor([0.6261])), ('bias', tensor([0.3308]))])\n",
            "Loss : 0.014840595424175262  ==  epoch=128\n",
            "OrderedDict([('weights', tensor([0.6279])), ('bias', tensor([0.3303]))])\n",
            "Loss : 0.01449323259294033  ==  epoch=129\n",
            "OrderedDict([('weights', tensor([0.6295])), ('bias', tensor([0.3293]))])\n",
            "Loss : 0.014155393466353416  ==  epoch=130\n",
            "OrderedDict([('weights', tensor([0.6313])), ('bias', tensor([0.3288]))])\n",
            "Loss : 0.013806397095322609  ==  epoch=131\n",
            "OrderedDict([('weights', tensor([0.6331])), ('bias', tensor([0.3283]))])\n",
            "Loss : 0.013468016870319843  ==  epoch=132\n",
            "OrderedDict([('weights', tensor([0.6347])), ('bias', tensor([0.3273]))])\n",
            "Loss : 0.013121193274855614  ==  epoch=133\n",
            "OrderedDict([('weights', tensor([0.6365])), ('bias', tensor([0.3268]))])\n",
            "Loss : 0.01277900766581297  ==  epoch=134\n",
            "OrderedDict([('weights', tensor([0.6381])), ('bias', tensor([0.3258]))])\n",
            "Loss : 0.012435992248356342  ==  epoch=135\n",
            "OrderedDict([('weights', tensor([0.6399])), ('bias', tensor([0.3253]))])\n",
            "Loss : 0.01208999752998352  ==  epoch=136\n",
            "OrderedDict([('weights', tensor([0.6415])), ('bias', tensor([0.3243]))])\n",
            "Loss : 0.011750795878469944  ==  epoch=137\n",
            "OrderedDict([('weights', tensor([0.6433])), ('bias', tensor([0.3238]))])\n",
            "Loss : 0.011401787400245667  ==  epoch=138\n",
            "OrderedDict([('weights', tensor([0.6451])), ('bias', tensor([0.3233]))])\n",
            "Loss : 0.011064787395298481  ==  epoch=139\n",
            "OrderedDict([('weights', tensor([0.6467])), ('bias', tensor([0.3223]))])\n",
            "Loss : 0.010716589167714119  ==  epoch=140\n",
            "OrderedDict([('weights', tensor([0.6485])), ('bias', tensor([0.3218]))])\n",
            "Loss : 0.010375778190791607  ==  epoch=141\n",
            "OrderedDict([('weights', tensor([0.6501])), ('bias', tensor([0.3208]))])\n",
            "Loss : 0.010031387209892273  ==  epoch=142\n",
            "OrderedDict([('weights', tensor([0.6519])), ('bias', tensor([0.3203]))])\n",
            "Loss : 0.009686763398349285  ==  epoch=143\n",
            "OrderedDict([('weights', tensor([0.6534])), ('bias', tensor([0.3193]))])\n",
            "Loss : 0.009346187114715576  ==  epoch=144\n",
            "OrderedDict([('weights', tensor([0.6552])), ('bias', tensor([0.3188]))])\n",
            "Loss : 0.008997755125164986  ==  epoch=145\n",
            "OrderedDict([('weights', tensor([0.6568])), ('bias', tensor([0.3178]))])\n",
            "Loss : 0.008660981431603432  ==  epoch=146\n",
            "OrderedDict([('weights', tensor([0.6586])), ('bias', tensor([0.3173]))])\n",
            "Loss : 0.008311985060572624  ==  epoch=147\n",
            "OrderedDict([('weights', tensor([0.6604])), ('bias', tensor([0.3168]))])\n",
            "Loss : 0.007972544990479946  ==  epoch=148\n",
            "OrderedDict([('weights', tensor([0.6620])), ('bias', tensor([0.3158]))])\n",
            "Loss : 0.007626785431057215  ==  epoch=149\n",
            "OrderedDict([('weights', tensor([0.6638])), ('bias', tensor([0.3153]))])\n",
            "Loss : 0.0072835334576666355  ==  epoch=150\n",
            "OrderedDict([('weights', tensor([0.6654])), ('bias', tensor([0.3143]))])\n",
            "Loss : 0.006941580679267645  ==  epoch=151\n",
            "OrderedDict([('weights', tensor([0.6672])), ('bias', tensor([0.3138]))])\n",
            "Loss : 0.006594526115804911  ==  epoch=152\n",
            "OrderedDict([('weights', tensor([0.6688])), ('bias', tensor([0.3128]))])\n",
            "Loss : 0.006256377790123224  ==  epoch=153\n",
            "OrderedDict([('weights', tensor([0.6706])), ('bias', tensor([0.3123]))])\n",
            "Loss : 0.005907376762479544  ==  epoch=154\n",
            "OrderedDict([('weights', tensor([0.6724])), ('bias', tensor([0.3118]))])\n",
            "Loss : 0.005569315515458584  ==  epoch=155\n",
            "OrderedDict([('weights', tensor([0.6740])), ('bias', tensor([0.3108]))])\n",
            "Loss : 0.005222178064286709  ==  epoch=156\n",
            "OrderedDict([('weights', tensor([0.6758])), ('bias', tensor([0.3103]))])\n",
            "Loss : 0.004880306776612997  ==  epoch=157\n",
            "OrderedDict([('weights', tensor([0.6774])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.004536976106464863  ==  epoch=158\n",
            "OrderedDict([('weights', tensor([0.6792])), ('bias', tensor([0.3088]))])\n",
            "Loss : 0.00419129803776741  ==  epoch=159\n",
            "OrderedDict([('weights', tensor([0.6808])), ('bias', tensor([0.3078]))])\n",
            "Loss : 0.0038517764769494534  ==  epoch=160\n",
            "OrderedDict([('weights', tensor([0.6826])), ('bias', tensor([0.3073]))])\n",
            "Loss : 0.0035027749836444855  ==  epoch=161\n",
            "OrderedDict([('weights', tensor([0.6844])), ('bias', tensor([0.3068]))])\n",
            "Loss : 0.0031660839449614286  ==  epoch=162\n",
            "OrderedDict([('weights', tensor([0.6860])), ('bias', tensor([0.3058]))])\n",
            "Loss : 0.002817571861669421  ==  epoch=163\n",
            "OrderedDict([('weights', tensor([0.6878])), ('bias', tensor([0.3053]))])\n",
            "Loss : 0.0024770735763013363  ==  epoch=164\n",
            "OrderedDict([('weights', tensor([0.6894])), ('bias', tensor([0.3043]))])\n",
            "Loss : 0.0021323717664927244  ==  epoch=165\n",
            "OrderedDict([('weights', tensor([0.6912])), ('bias', tensor([0.3038]))])\n",
            "Loss : 0.0017880648374557495  ==  epoch=166\n",
            "OrderedDict([('weights', tensor([0.6927])), ('bias', tensor([0.3028]))])\n",
            "Loss : 0.0014518328243866563  ==  epoch=167\n",
            "OrderedDict([('weights', tensor([0.6947])), ('bias', tensor([0.3028]))])\n",
            "Loss : 0.0011887758737429976  ==  epoch=168\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=169\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=170\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=171\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=172\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=173\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=174\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=175\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=176\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=177\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=178\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=179\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=180\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=181\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=182\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=183\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=184\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=185\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=186\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=187\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=188\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=189\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=190\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=191\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=192\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=193\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=194\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=195\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=196\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=197\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=198\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=199\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=200\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=201\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=202\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=203\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=204\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=205\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=206\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=207\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=208\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=209\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=210\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=211\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=212\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=213\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=214\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=215\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=216\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=217\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=218\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=219\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=220\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=221\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=222\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=223\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=224\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=225\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=226\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=227\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=228\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=229\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=230\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=231\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=232\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=233\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=234\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=235\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=236\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=237\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=238\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=239\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=240\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=241\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=242\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=243\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=244\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=245\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=246\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=247\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=248\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=249\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=250\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=251\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=252\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=253\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=254\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=255\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=256\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=257\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=258\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=259\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=260\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=261\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=262\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=263\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=264\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=265\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=266\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=267\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=268\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=269\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=270\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=271\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=272\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=273\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=274\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=275\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=276\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=277\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=278\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=279\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=280\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=281\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=282\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=283\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=284\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=285\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=286\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=287\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=288\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=289\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=290\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=291\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=292\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=293\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=294\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=295\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=296\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=297\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=298\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=299\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=300\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=301\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=302\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=303\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=304\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=305\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=306\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=307\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=308\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=309\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=310\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=311\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=312\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=313\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=314\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=315\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=316\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=317\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=318\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=319\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=320\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=321\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=322\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=323\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=324\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=325\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=326\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=327\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=328\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=329\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=330\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=331\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=332\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=333\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=334\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=335\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=336\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=337\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=338\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=339\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=340\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=341\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=342\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=343\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=344\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=345\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=346\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=347\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=348\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=349\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=350\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=351\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=352\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=353\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=354\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=355\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=356\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=357\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=358\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=359\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=360\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=361\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=362\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=363\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=364\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=365\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=366\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=367\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=368\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=369\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=370\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=371\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=372\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=373\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=374\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=375\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=376\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=377\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=378\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=379\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=380\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=381\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=382\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=383\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=384\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=385\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=386\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=387\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=388\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=389\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=390\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=391\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=392\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=393\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=394\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=395\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=396\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=397\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=398\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=399\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=400\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=401\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=402\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=403\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=404\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=405\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=406\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=407\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=408\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=409\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=410\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=411\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=412\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=413\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=414\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=415\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=416\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=417\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=418\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=419\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=420\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=421\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=422\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=423\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=424\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=425\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=426\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=427\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=428\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=429\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=430\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=431\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=432\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=433\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=434\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=435\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=436\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=437\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=438\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=439\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=440\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=441\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=442\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=443\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=444\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=445\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=446\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=447\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=448\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=449\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=450\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=451\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=452\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=453\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=454\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=455\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=456\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=457\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=458\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=459\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=460\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=461\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=462\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=463\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=464\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=465\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=466\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=467\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=468\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=469\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=470\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=471\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=472\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=473\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=474\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=475\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=476\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=477\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=478\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=479\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=480\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=481\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=482\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=483\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=484\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=485\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=486\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=487\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=488\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=489\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=490\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=491\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=492\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=493\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=494\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=495\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=496\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=497\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=498\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=499\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=500\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=501\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=502\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=503\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=504\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=505\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=506\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=507\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=508\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=509\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=510\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=511\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=512\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=513\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=514\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=515\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=516\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=517\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=518\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=519\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=520\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=521\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=522\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=523\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=524\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=525\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=526\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=527\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=528\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=529\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=530\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=531\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=532\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=533\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=534\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=535\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=536\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=537\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=538\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=539\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=540\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=541\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=542\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=543\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=544\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=545\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=546\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=547\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=548\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=549\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=550\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=551\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=552\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=553\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=554\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=555\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=556\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=557\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=558\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=559\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=560\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=561\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=562\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=563\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=564\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=565\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=566\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=567\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=568\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=569\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=570\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=571\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=572\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=573\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=574\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=575\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=576\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=577\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=578\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=579\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=580\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=581\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=582\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=583\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=584\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=585\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=586\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=587\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=588\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=589\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=590\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=591\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=592\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=593\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=594\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=595\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=596\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=597\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=598\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=599\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=600\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=601\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=602\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=603\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=604\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=605\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=606\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=607\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=608\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=609\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=610\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=611\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=612\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=613\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=614\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=615\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=616\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=617\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=618\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=619\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=620\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=621\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=622\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=623\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=624\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=625\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=626\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=627\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=628\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=629\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=630\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=631\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=632\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=633\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=634\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=635\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=636\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=637\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=638\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=639\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=640\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=641\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=642\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=643\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=644\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=645\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=646\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=647\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=648\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=649\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=650\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=651\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=652\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=653\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=654\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=655\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=656\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=657\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=658\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=659\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=660\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=661\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=662\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=663\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=664\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=665\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=666\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=667\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=668\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=669\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=670\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=671\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=672\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=673\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=674\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=675\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=676\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=677\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=678\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=679\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=680\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=681\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=682\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=683\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=684\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=685\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=686\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=687\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=688\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=689\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=690\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=691\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=692\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=693\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=694\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=695\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=696\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=697\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "Loss : 0.008932482451200485  ==  epoch=698\n",
            "OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
            "Loss : 0.0025885067880153656  ==  epoch=699\n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_model.state_dict()\n",
        "\n",
        "with torch.inference_mode():\n",
        "  y_preds = my_model(X_test)\n",
        "y_preds\n",
        "\n",
        "plot_data_and_predictions(predictions=y_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "6FusOtTlnqYe",
        "outputId": "14ba4d42-c753-4367-d418-cf1ba95eca3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAAGbCAYAAADgEhWsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAt/UlEQVR4nO3de3xU9Z3/8feHDJfITZQAchEQUcGIChGlVkHFVblIXddysRZWq/EH/Fa34qXaclNrW7GsXaM7ahXrXRFdFinWsuCtAgkgrBCwiBfACMHtzwtUIZPP74+kaRKTzIQzk5nMvJ6PRx7JOec753ySE+DNd77zGXN3AQAA4NC0SHYBAAAAzRlhCgAAIADCFAAAQACEKQAAgAAIUwAAAAGEknXhzp07e58+fZJ1eQAAgJitXbt2r7vn1HUsaWGqT58+KioqStblAQAAYmZmH9V3jKf5AAAAAiBMAQAABECYAgAACIAwBQAAEABhCgAAIICor+Yzs0ckjZG0x91z6zhuku6VNErSfklT3H1d0MK++OIL7dmzRwcPHgx6KqS5li1bqkuXLurQoUOySwEAZKBYWiMskHSfpN/Vc/wiSf0rP06X9EDl50P2xRdfaPfu3erRo4eys7NVkdeAb3N3/fWvf9WuXbskiUAFAGhyUZ/mc/fXJf1vA0PGSfqdV1gl6XAzOypIUXv27FGPHj102GGHEaTQIDPTYYcdph49emjPnj3JLgcAkIHisWaqh6Qd1bZ3Vu47ZAcPHlR2dnagopBZsrOzeUoYAJAUTboA3cyuMbMiMysqLS2NNraJqkI64PcFAJAs8QhTuyT1qrbds3Lft7j7g+6e5+55OTl1vr0NAABAsxKPMLVY0g+twhmSPnf3kjicFwAAIOVFDVNm9rSktyUdb2Y7zewqM7vWzK6tHLJU0nZJ2yQ9JGlqwqrNQFOmTNGYMWMa9ZgRI0Zo+vTpCaqoYdOnT9eIESOScm0AAJIhamsEd58Y5bhLmha3ipqpaGt2Jk+erAULFjT6vPfee68qfsSxW7RokVq2bNnoayXDhx9+qL59+6qwsFB5eXnJLgcAgEaLpc8UYlBS8vdnNpcsWaKrr766xr7ar048ePBgTIGnY8eOja7liCOOaPRjAADAoeHtZOKkW7duVR+HH354jX1ff/21Dj/8cD399NM699xzlZ2drXA4rM8++0wTJ05Uz549lZ2drRNPPFGPPvpojfPWfppvxIgRmjp1qm699VZ17txZXbp00YwZM1ReXl5jTPWn+fr06aM77rhD+fn56tChg3r27Km77767xnXee+89DR8+XG3atNHxxx+vpUuXql27dg3OpkUiEc2YMUOdOnVSp06ddP311ysSidQYs2zZMp111lnq1KmTjjjiCF1wwQUqLi6uOt63b19J0mmnnSYzq3qKsLCwUP/wD/+gzp07q0OHDvrud7+rt99+O/qNAABklGkvT1NobkjTXk7ek2SEqSb0k5/8RFOnTtXmzZv1ve99T19//bUGDx6sJUuWaNOmTbruuuuUn5+v5cuXN3ieJ598UqFQSH/6059033336d/+7d/07LPPNviY+fPn66STTtK6det0880366abbqoKJ+Xl5brkkksUCoW0atUqLViwQHPmzNE333zT4DnvuecePfTQQwqHw3r77bcViUT05JNP1hizb98+XX/99VqzZo1Wrlypjh07auzYsTpw4IAkac2aNZIqQldJSYkWLVokSfryyy91xRVX6I033tCaNWt0yimnaNSoUfrss88arAkAkFnCa8OKeEThteHkFeHuSfkYMmSI12fz5s31HmusqVOnelZWlk+dOjVu54zm+eef94ofbYUPPvjAJfm8efOiPnb8+PF+1VVXVW1PnjzZR48eXbU9fPhwP+OMM2o8ZuTIkTUeM3z4cJ82bVrVdu/evX3ChAk1HnPsscf67bff7u7uy5Yt86ysLN+5c2fV8bfeessl+aOPPlpvrUcddZTfcccdVduRSMT79+/vw4cPr/cxX331lbdo0cLfeOMNd//7z6awsLDex7i7l5eXe7du3fzxxx+vd0w8f28AAM3DytG5ftDkK0fnJvQ6koq8nkyT9jNT4XBYkUhE4XASE2ul2gusI5GI7rzzTg0aNEhHHnmk2rVrp0WLFunjjz9u8DyDBg2qsd29e/eob6XS0GO2bNmi7t27q0ePvzeuP+2009SiRf2/Hp9//rlKSko0bNiwqn0tWrTQ6afXfFvG999/X5MmTVK/fv3UoUMHde3aVeXl5VG/xz179ig/P1/HHXecOnbsqPbt22vPnj1RHwcAyCzDlxUr5BWfkyXtw1R+fr6ysrKUn5+f7FLUtm3bGtvz5s3TPffcoxtvvFHLly/XO++8o+9973tVT4HVp/bCdTOrsWYqXo+JhzFjxqi0tFThcFirV6/W+vXrFQqFon6PkydPVmFhoebPn68//elPeuedd9SzZ8+ojwMAZJj8fCkrq+JzkqT9q/kKCgpUUFCQ7DLq9Oabb2rs2LG64oorJFU85free+9VLWBvKieccII++eQTffLJJ+revbskqaioqMGw1bFjRx111FFatWqVzj33XEkV9a9Zs0ZHHVXxPtefffaZtmzZovvvv1/nnHOOJGndunUqKyurOk+rVq0k6VsL199880395je/0ejRoyVJu3fvrvHqSAAAJEkFBRUfSZT2M1Op7LjjjtPy5cv15ptvasuWLZo+fbo++OCDJq/j/PPP1/HHH6/Jkydrw4YNWrVqlX784x8rFAo12D/ruuuu069+9SstXLhQW7du1fXXX18j8HTq1EmdO3fWQw89pG3btum1117Ttddeq1Do7xm+S5cuys7O1iuvvKLdu3fr888/l1Txs3niiSe0efNmFRYWasKECVXBCwCAVEKYSqKf/vSnGjp0qC666CKdffbZatu2rS6//PImr6NFixZ68cUX9c0332jo0KGaPHmybrvtNpmZ2rRpU+/jbrjhBv3zP/+zfvSjH+n0009XeXl5jfpbtGihZ599Vhs3blRubq6mTZum22+/Xa1bt64aEwqF9Jvf/EYPP/ywunfvrnHjxkmSHnnkEX311VcaMmSIJkyYoCuvvFJ9+vRJ2M8AAJA6UqHdQWOYN7K7drzk5eV5UVFRnceKi4s1YMCAJq4I1W3YsEGnnHKKioqKNGTIkGSXExN+bwAgPYTmhhTxiLIsS2Uzy6I/oAmY2Vp3r/OtOtJ+zRRi8+KLL6pt27bq37+/PvzwQ/34xz/WySefrMGDBye7NABAhlm+ZoDOXPqu3hrVPP6DTJiCpIommTfffLN27NihTp06acSIEZo/f37U9xwEACDehi8rlpLc7qAxCFOQJP3whz/UD3/4w2SXAQBARZuDcDip7Q4agzAFAABSSwq0O2gMXs0HAAAQAGEKAAA0iebW8iBWhCkAANAkwmvDinhE4bXJf7/ceCJMAQCAJrF8zQAdnFPxOZ2wAB0AADSJ5tbyIFbMTDVjffr00bx585Jy7TFjxmjKlClJuTYAoJnKz5eysppNy4NYEabixMwa/AgSPGbPnq3c3Nxv7S8sLNTUqVMDVN10Vq5cKTPT3r17k10KACBZCgqksrJm1fYgFjzNFyclJSVVXy9ZskRXX311jX3Z2dlxv2ZOTk7czwkAABqHmak46datW9XH4Ycf/q19r7/+uoYMGaI2bdqob9++uu2223TgwIGqxy9atEiDBg1Sdna2jjjiCA0fPly7d+/WggULNGfOHG3atKlqlmvBggWSvv00n5npwQcf1GWXXaa2bdvqmGOO0RNPPFGjztWrV2vw4MFq06aNTj31VC1dulRmppUrV9b7ve3fv19TpkxRu3bt1LVrV/385z//1pgnnnhCp512mtq3b68uXbrosssu065duyRJH374oc455xxJFQGw+kzdsmXLdNZZZ6lTp0464ogjdMEFF6i4OL2eSweAdJeuLQ9iRZhqAq+88oouv/xyTZ8+XZs2bdIjjzyihQsX6tZbb5Ukffrpp5owYYImT56s4uJivf7667riiiskSePHj9cNN9yg448/XiUlJSopKdH48ePrvdbcuXM1btw4bdiwQePHj9eVV16pjz/+WJL01VdfacyYMTrhhBO0du1a/epXv9KNN94Ytf4ZM2bo1Vdf1QsvvKDly5dr/fr1ev3112uMOXDggObMmaMNGzZoyZIl2rt3ryZOnChJ6tWrl1544QVJ0qZNm1RSUqJ7771XkrRv3z5df/31WrNmjVauXKmOHTtq7NixNYImACC1pWvLg5i5e1I+hgwZ4vXZvHlzvccaa+qSqZ41J8unLpkat3NG8/zzz3vFj7bCWWed5XPnzq0x5sUXX/S2bdt6eXm5r1271iX5hx9+WOf5Zs2a5SeeeOK39vfu3dvvvvvuqm1Jfsstt1RtHzx40LOzs/3xxx93d/f/+I//8E6dOvn+/furxjz55JMuyVesWFHntb/88ktv1aqVP/HEEzX2dezY0SdPnlzvz6C4uNgl+Y4dO9zdfcWKFS7JS0tL632Mu/tXX33lLVq08DfeeKPBcXWJ5+8NACB2K0fn+kGTrxydm+xSEkZSkdeTadJ+ZioV0vLatWt15513ql27dlUfkyZN0r59+/Tpp5/q5JNP1siRI5Wbm6tLL71UDzzwgEpLSw/pWoMGDar6OhQKKScnR3v27JEkbdmyRbm5uTXWb51++ukNnu/999/XgQMHNGzYsKp97dq100knnVRj3Lp16zRu3Dj17t1b7du3V15eniRVzYo1dP5JkyapX79+6tChg7p27ary8vKojwMApI7hy4oVSsOWB7FK+zCVPyRfWZal/CHJexlmeXm5Zs2apXfeeafqY+PGjfrzn/+snJwcZWVl6Q9/+IP+8Ic/aNCgQfrtb3+r/v37a8OGDY2+VsuWLWtsm5nKy8vj9a3Uad++fbrgggt02GGH6fHHH1dhYaGWLVsmSVGfrhszZoxKS0sVDoe1evVqrV+/XqFQiKf5AKA5SdOWB7FK+1fzFYwuUMHo5L4Ec/DgwdqyZYuOPfbYeseYmYYNG6Zhw4Zp5syZOvHEE/Xss8/q5JNPVqtWrRSJRALXccIJJ+ixxx7TX//616rZqTVr1jT4mH79+qlly5ZatWqVjjnmGEkV4endd99Vv379JFXMeO3du1c///nP1bdvX0kVC+qra9WqlSTV+D4+++wzbdmyRffff3/VAvV169aprKws8PcKAGhCBQVp1+6gMdJ+ZioVzJw5U0899ZRmzpypd999V1u2bNHChQt10003SZJWrVqlO+64Q4WFhfr444+1ePFi7dixQwMHDpRU8aq9jz76SOvWrdPevXv1zTffHFIdkyZNUlZWlq6++mpt3rxZf/zjH6temWdmdT6mXbt2uuqqq3TzzTfr1Vdf1aZNm3TllVfWCEVHH320Wrdurfvuu0/bt2/Xyy+/rJ/97Gc1ztO7d2+ZmV5++WWVlpbqq6++UqdOndS5c2c99NBD2rZtm1577TVde+21CoXSPuMDANIIYaoJXHDBBXr55Ze1YsUKDR06VEOHDtUvfvELHX300ZKkjh076q233tKYMWPUv39/3XDDDfrZz36mH/zgB5KkSy+9VKNGjdJ5552nnJwcPf3004dUR/v27fVf//Vf2rRpk0499VTdeOONmj17tiSpTZs29T5u3rx5Ouecc3TJJZfonHPOUW5urs4+++yq4zk5OXrsscf00ksvaeDAgZozZ45+/etf1zhHjx49NGfOHN12223q2rWrpk+frhYtWujZZ5/Vxo0blZubq2nTpun2229X69atD+n7AwDET6a3O2gMq1ig3vTy8vK8qKiozmPFxcUaMCC93gQxVf3nf/6nLrnkEu3Zs0edO3dOdjmB8HsDAPETmhtSxCPKsiyVzWT5hZmtdfe8uo7xfEqGeeyxx3TMMceoV69eevfdd3X99ddr7NixzT5IAQDia/maATpz6bt6axT/SY2GMJVhdu/erVmzZqmkpETdunXT6NGj9ctf/jLZZQEAUszwZcVSBrc7aAzCVIa56aabqha+AwBQr/x8KRzO2HYHjUGYAgAA35bh7Q4ag1fzAQAABECYAgAgg9DyIP4IUwAAZJBUeM/adEOYAgAggyxfM0AH51R8RnywAB0AgAxCy4P4Y2aqGVq4cGGN99JbsGCB2rVrF+icK1eulJlp7969QcsDAKSy/HwpK4uWB3FEmIqjKVOmyMxkZmrZsqWOOeYYzZgxQ/v27UvodcePH6/t27fHPL5Pnz6aN29ejX3f+c53VFJSoiOPPDLe5QEAUklBgVRWRtuDOIopTJnZhWa21cy2mdktdRzvbWbLzWyjma00s57xL7V5GDlypEpKSrR9+3bdcccduv/++zVjxoxvjSsrK1O83hcxOztbXbp0CXSOVq1aqVu3bjVmvAAAQHRRw5SZZUkqkHSRpIGSJprZwFrD5kn6nbsPkjRX0l3xLrS5aN26tbp166ZevXpp0qRJuvzyy/XSSy9p9uzZys3N1YIFC9SvXz+1bt1a+/bt0+eff65rrrlGXbp0Ufv27TV8+HDVfgPo3/3ud+rdu7cOO+wwjRkzRrt3765xvK6n+ZYuXarTTz9d2dnZOvLIIzV27Fh9/fXXGjFihD766CPdeOONVbNoUt1P8y1atEgnnXSSWrdurV69eunOO++sEQD79OmjO+64Q/n5+erQoYN69uypu+++u0Yd4XBYxx13nNq0aaPOnTvrggsuUFkZb5gJAPFGy4PkiWVmaqikbe6+3d0PSHpG0rhaYwZK+u/Kr1fUcTxjZWdn6+DBg5KkDz74QE899ZSef/55bdiwQa1bt9bo0aO1a9cuLVmyROvXr9fZZ5+tc889VyUlJZKk1atXa8qUKbrmmmv0zjvvaOzYsZo5c2aD11y2bJkuvvhinX/++Vq7dq1WrFih4cOHq7y8XIsWLVLPnj01c+ZMlZSUVF2ntrVr1+qyyy7TP/7jP+p//ud/9Itf/EJ33XWX7rvvvhrj5s+fr5NOOknr1q3TzTffrJtuuklvv/22JKmoqEjTpk3TrFmztHXrVi1fvlwXXnhh0B8pAKAOtDxIIndv8EPSP0l6uNr2FZLuqzXmKUnXVX79j5Jc0pF1nOsaSUWSio4++mivz+bNm+s91mhTp7pnZVV8TrDJkyf76NGjq7ZXr17tRx55pH//+9/3WbNmeSgU8k8//bTq+PLly71t27a+f//+Guc5+eST/Ze//KW7u0+cONFHjhxZ4/hVV13lFbeuwqOPPupt27at2v7Od77j48ePr7fO3r17+913311j34oVK1ySl5aWurv7pEmT/JxzzqkxZtasWd6jR48a55kwYUKNMccee6zffvvt7u7+wgsveIcOHfyLL76ot5Z4iuvvDQA0MytH5/pBk68cnZvsUtKSpCKvJyvFawH6DEnDzWy9pOGSdkmK1BHcHnT3PHfPy8nJidOlowiHpUik4nMTWLZsmdq1a6c2bdpo2LBhOvvss/Xv//7vkqSePXuqa9euVWPXrl2r/fv3KycnR+3atav6ePfdd/X+++9LkoqLizVs2LAa16i9Xdv69et13nnnBfo+iouLdeaZZ9bY993vfle7du3SF198UbVv0KBBNcZ0795de/bskSSdf/756t27t/r27avLL79cjz32mL788stAdQEA6jZ8WbFCtDxIilj6TO2S1Kvads/KfVXc/RNVzEjJzNpJutTd/1+cagymid/1+uyzz9aDDz6oli1bqnv37mrZsmXVsbZt29YYW15erq5du+qNN9741nk6dOiQ8FoPVfVF6tW/v78dKy8vlyS1b99e69at0+uvv65XX31Vd911l2699VYVFhaqe/fuTVozAKS9Jv73Dn8Xy8xUoaT+ZtbXzFpJmiBpcfUBZtbZzP52rp9IeiS+ZQbQxC8BPeyww3Tssceqd+/e3woatQ0ePFi7d+9WixYtdOyxx9b4+Nur8wYMGKBVq1bVeFzt7dpOPfVULV++vN7jrVq1UiTyrYnDGgYMGKC33nqrxr4333xTPXv2VPv27Rt8bHWhUEjnnnuu7rrrLm3cuFH79u3TkiVLYn48ACBGtDxImqhhyt3LJE2X9IqkYknPufsmM5trZhdXDhshaauZvSepq6Q7E1RvWhk5cqTOPPNMjRs3Tr///e/1wQcf6O2339asWbOqZqv+5V/+RX/84x9111136c9//rMeeughvfjiiw2e97bbbtPzzz+vn/70p9q8ebM2bdqk+fPna//+/ZIqXoX3xhtvaNeuXfU26bzhhhv02muvafbs2Xrvvff05JNP6p577tFNN90U8/e3ZMkS3XvvvVq/fr0++ugjPfXUU/ryyy81YABvYQAASB8xrZly96Xufpy793P3Oyv3zXT3xZVfL3T3/pVjfuTu3ySy6HRhZlq6dKnOPfdcXX311Tr++OP1/e9/X1u3bq16GuyMM87Qb3/7Wz3wwAMaNGiQFi1apNmzZzd43lGjRunFF1/U73//e5166qkaPny4VqxYoRYtKm733LlztWPHDvXr10/1rV0bPHiwnn/+eb3wwgvKzc3VLbfcoltuuUXTp0+P+fs7/PDD9dJLL2nkyJE64YQTNG/ePD388MM666yzYj4HAGQy2h00D+ZxahzZWHl5eV67n9LfFBcXM3uBRuP3BkC6Cc0NKeIRZVmWymbSoy+ZzGytu+fVdYy3kwEAIEUtXzNAB+dUfEbqiuXVfAAAIAmGLyuWaHeQ8piZAgAgVeXnS1lZtDtIccxMAQCQqgoKaHXQDKTszNTfGj8CseD3BQCQLCkZptq2batdu3bpwIEDStarDdE8uLsOHDigXbt2favDPACkKloepJeUbI1QXl6uvXv36vPPP1dZGS8FRcNCoZA6duyozp07V/XSAoBURsuD5qeh1ggpuWaqRYsW6tKlS9VbqgAAkE6WrxmgM5e+q7dG0fIgHaRkmAIAIJ3R8iC98JwIAABNjZYHaSUl10wBAACkEt5OBgAAIEEIUwAAxAktDzITYQoAgDgJrw0r4hGF14aTXQqaEGEKAIA4Wb5mgA7OqfiMzEFrBAAA4oSWB5mJmSkAAOKFlgcZidYIAAAAUdAaAQAAIEEIUwAANGDatGkKhUKaNo12B6gbT/MBANCAUCikSCSirKwslZWVJbscJAlP8wEAcIjy8/OVlZWlfBaVox7MTAEAAETBzBQAAECCEKYAAAACIEwBAAAEQJgCAGQkWh4gXliADgDISLQ8QGOwAB0AgFpoeYB4YWYKAAAgCmamAAAAEoQwBQAAEABhCgAAIADCFAAgbdDuAMnAAnQAQNqg3QEShQXoAICMQLsDJAMzUwAAAFEwMwUAAJAghCkAAIAACFMAAAABxBSmzOxCM9tqZtvM7JY6jh9tZivMbL2ZbTSzUfEvFQCQqWh5gFQWdQG6mWVJek/S+ZJ2SiqUNNHdN1cb86Ck9e7+gJkNlLTU3fs0dF4WoAMAYkXLAyRb0AXoQyVtc/ft7n5A0jOSxtUa45I6VH7dUdInh1osAAC10fIAqSyWmal/knShu/+ocvsKSae7+/RqY46S9AdJnSS1lTTS3dfWca5rJF0jSUcfffSQjz76KF7fBwAAQMI0RWuEiZIWuHtPSaMkPW5m3zq3uz/o7nnunpeTkxOnSwMAACRPLGFql6Re1bZ7Vu6r7ipJz0mSu78tqY2kzvEoEAAAIJXFEqYKJfU3s75m1krSBEmLa435WNJ5kmRmA1QRpkrjWSgAAEAqihqm3L1M0nRJr0gqlvScu28ys7lmdnHlsBskXW1mGyQ9LWmKJ+t9agAAzQYtD5AOeG8+AEDS0PIAzQXvzQcASEm0PEA6YGYKAAAgCmamAAAAEoQwBQAAEABhCgAAIADCFAAgrmh3gEzDAnQAQFzR7gDpiAXoAIAmQ7sDZBpmpgAAAKJgZgoAACBBCFMAAAABEKYAAAACIEwBAAAEQJgCAMSE/lFA3Xg1HwAgJvSPQibj1XwAgMDoHwXUjZkpAACAKJiZAgAASBDCFAAAQACEKQAAgAAIUwCQ4Wh5AATDAnQAyHC0PACiYwE6AKBetDwAgmFmCgAAIApmpgAAABKEMAUAABAAYQoAACAAwhQApCHaHQBNhwXoAJCGaHcAxBcL0AEgw9DuAGg6zEwBAABEwcwUAABAghCmAAAAAiBMAQAABECYAoBmhJYHQOphAToANCO0PACSgwXoAJAmaHkApB5mpgAAAKJgZgoAACBBCFMAAAABEKYAAAACIEwBQAqg5QHQfMW0AN3MLpR0r6QsSQ+7+y9qHZ8v6ZzKzcMkdXH3wxs6JwvQAeDvaHkApLZAC9DNLEtSgaSLJA2UNNHMBlYf4+7/6u6nuPspkv5d0qLAVQNABqHlAdB8xfI031BJ29x9u7sfkPSMpHENjJ8o6el4FAcAmaKgoEBlZWUqKChIdikAGimWMNVD0o5q2zsr932LmfWW1FfSf9dz/BozKzKzotLS0sbWCgAAkHLivQB9gqSF7h6p66C7P+juee6el5OTE+dLAwAANL1YwtQuSb2qbfes3FeXCeIpPgAAkEFiCVOFkvqbWV8za6WKwLS49iAzO0FSJ0lvx7dEAGieaHcAZIaoYcrdyyRNl/SKpGJJz7n7JjOba2YXVxs6QdIznqw3+wOAFBMOhxWJRBQOh5NdCoAECsUyyN2XSlpaa9/MWtuz41cWADR/+fn5CofDtDsA0lxMTTsTgaadAACguQjUtBMAAAD1I0wBAAAEQJgCAAAIgDAFAI1EywMA1bEAHQAaKRQKKRKJKCsrS2VlZckuB0ATYAE6AMRRfn6+srKyaHkAQBIzUwAAAFExMwUAAJAghCkAAIAACFMAAAABEKYAoBItDwAcChagA0AlWh4AqA8L0AEgBrQ8AHAomJkCAACIgpkpAACABCFMAQAABECYAgAACIAwBSCt0e4AQKKxAB1AWqPdAYB4YAE6gIxFuwMAicbMFAAAQBTMTAEAACQIYQoAACAAwhQAAEAAhCkAzRItDwCkChagA2iWaHkAoCmxAB1A2qHlAYBUwcwUAABAFMxMAQAAJAhhCgAAIADCFAAAQACEKQAphZYHAJobFqADSCm0PACQiliADqDZoOUBgOaGmSkAAIAomJkCAABIEMIUAABAAIQpAACAAAhTABKOdgcA0hkL0AEkHO0OADR3gRegm9mFZrbVzLaZ2S31jPm+mW02s01m9lSQggGkF9odAEhnUWemzCxL0nuSzpe0U1KhpInuvrnamP6SnpN0rrv/xcy6uPuehs7LzBQAAGgugs5MDZW0zd23u/sBSc9IGldrzNWSCtz9L5IULUgBAACki1jCVA9JO6pt76zcV91xko4zs7fMbJWZXVjXiczsGjMrMrOi0tLSQ6sYAAAghcTr1XwhSf0ljZA0UdJDZnZ47UHu/qC757l7Xk5OTpwuDQAAkDyxhKldknpV2+5Zua+6nZIWu/tBd/9AFWus+senRACpipYHABBbmCqU1N/M+ppZK0kTJC2uNeYlVcxKycw6q+Jpv+3xKxNAKgqHw4pEIgqHw8kuBQCSJmqYcvcySdMlvSKpWNJz7r7JzOaa2cWVw16R9JmZbZa0QtKN7v5ZoooGkBpoeQAANO0EAACIKnDTTgAAANSNMAUAABAAYQoAACAAwhSAGmh3AACNwwJ0ADWEQiFFIhFlZWWprKws2eUAQEpgATqAmNHuAAAah5kpAACAKJiZAgAASBDCFAAAQACEKQAAgAAIU0CGoOUBACQGC9CBDEHLAwA4dCxAB0DLAwBIEGamAAAAomBmCgAAIEEIUwAAAAEQpgAAAAIgTAHNHC0PACC5WIAONHO0PACAxGMBOpDGaHkAAMnFzBQAAEAUzEwBAAAkCGEKAAAgAMIUAABAAIQpIAXR7gAAmg8WoAMpiHYHAJBaWIAONDO0OwCA5oOZKQAAgCiYmQIAAEgQwhQAAEAAhCkAAIAACFMAAAABEKaAJkT/KABIP7yaD2hC9I8CgOaJV/MBKYL+UQCQfpiZAgAAiIKZKQAAgAQhTAEAAARAmAIAAAiAMAXEAS0PACBzsQAdiANaHgBAemMBOpBgtDwAgMwVU5gyswvNbKuZbTOzW+o4PsXMSs3sncqPH8W/VCB1FRQUqKysTAUFBckuBQDQxELRBphZlqQCSedL2imp0MwWu/vmWkOfdffpCagRAAAgZcUyMzVU0jZ33+7uByQ9I2lcYssCAABoHmIJUz0k7ai2vbNyX22XmtlGM1toZr3qOpGZXWNmRWZWVFpaegjlAgAApJZ4LUD/L0l93H2QpFclPVbXIHd/0N3z3D0vJycnTpcGEoN2BwCAWMQSpnZJqj7T1LNyXxV3/8zdv6ncfFjSkPiUByRPOBxWJBJROBxOdikAgBQWS5gqlNTfzPqaWStJEyQtrj7AzI6qtnmxpOL4lQgkB+0OAACxiKlpp5mNkvRvkrIkPeLud5rZXElF7r7YzO5SRYgqk/S/kv6Pu29p6Jw07QQAAM1FQ0076YAOAAAQBR3QAQAAEoQwBQAAEABhChmHlgcAgHhizRQyTigUUiQSUVZWlsrKypJdDgCgGWDNFFANLQ8AAPHEzBQAAEAUzEwBAAAkCGEKAAAgAMIUAABAAIQppA1aHgAAkoEF6EgbtDwAACQKC9CREWh5AABIBmamAAAAomBmCgAAIEEIUwAAAAEQpgAAAAIgTCGl0e4AAJDqWICOlEa7AwBAKmABOpot2h0AAFIdM1MAAABRMDMFAACQIIQpAACAAAhTAAAAARCmkBS0PAAApAsWoCMpaHkAAGhOWICOlEPLAwBAumBmCgAAIApmpgAAABKEMAUAABAAYQoAACAAwhTiipYHAIBMwwJ0xBUtDwAA6YgF6GgytDwAAGQaZqYAAACiYGYKAAAgQQhTAAAAARCmAAAAAiBMISraHQAAUD8WoCMq2h0AADIdC9ARCO0OAACoHzNTAAAAUQSemTKzC81sq5ltM7NbGhh3qZm5mdV5MQAAgHQTNUyZWZakAkkXSRooaaKZDaxjXHtJ10laHe8iAQAAUlUsM1NDJW1z9+3ufkDSM5LG1THudkm/lPR1HOsDAABIabGEqR6SdlTb3lm5r4qZDZbUy91fbuhEZnaNmRWZWVFpaWmji0V80fIAAIDgAr+az8xaSPq1pBuijXX3B909z93zcnJygl4aAYXDYUUiEYXD4WSXAgBAsxVLmNolqVe17Z6V+/6mvaRcSSvN7ENJZ0hazCL01EfLAwAAgovaGsHMQpLek3SeKkJUoaRJ7r6pnvErJc1w9wb7HtAaAQAANBeBWiO4e5mk6ZJekVQs6Tl332Rmc83s4viWCgAA0LyEYhnk7kslLa21b2Y9Y0cELwsAAKB54O1kAAAAAiBMpSFaHgAA0HR4b740FAqFFIlElJWVpbKysmSXAwBAsxf4vfnQvNDyAACApsPMFAAAQBTMTAEAACQIYQoAACAAwhQAAEAAhKlmgnYHAACkJhagNxO0OwAAIHlYgJ4GaHcAAEBqYmYKAAAgCmamAAAAEoQwBQAAEABhCgAAIADCVJLR8gAAgOaNBehJRssDAABSHwvQUxgtDwAAaN6YmQIAAIiCmSkAAIAEIUwBAAAEQJgCAAAIgDCVALQ7AAAgc7AAPQFodwAAQHphAXoTo90BAACZg5kpAACAKJiZAgAASBDCFAAAQACEKQAAgAAIU41AywMAAFAbC9AbgZYHAABkJhagxwktDwAAQG3MTAEAAETBzBQAAECCEKYAAAACIEwBAAAEQJgSLQ8AAMChYwG6aHkAAAAaxgL0KGh5AAAADhUzUwAAAFEwMwUAAJAgMYUpM7vQzLaa2TYzu6WO49ea2f+Y2Ttm9qaZDYx/qQAAAKknapgysyxJBZIukjRQ0sQ6wtJT7n6Su58i6VeSfh3vQgEAAFJRLDNTQyVtc/ft7n5A0jOSxlUf4O5fVNtsKyk5C7EAAACaWCxhqoekHdW2d1buq8HMppnZ+6qYmfqX+JR36OgdBQAAmkLcFqC7e4G795N0s6Sf1jXGzK4xsyIzKyotLY3XpesUDocViUQUDocTeh0AAJDZYglTuyT1qrbds3JffZ6R9L26Drj7g+6e5+55OTk5MRd5KOgdBQAAmkLUPlNmFpL0nqTzVBGiCiVNcvdN1cb0d/c/V349VtKs+nox/A19pgAAQHPRUJ+pULQHu3uZmU2X9IqkLEmPuPsmM5srqcjdF0uabmYjJR2U9BdJk+NXPgAAQOqKGqYkyd2XSlpaa9/Mal9fF+e6AAAAmgU6oAMAAARAmAIAAAiAMAUAABAAYQoAACAAwhQAAEAAhCkAAIAACFMAAAABEKYAAAACIEwBAAAEQJgCAAAIgDAFAAAQAGEKAAAgAHP35FzYrFTSRwm+TGdJexN8DRw67k/q4t6kNu5PauP+pK4g96a3u+fUdSBpYaopmFmRu+cluw7UjfuTurg3qY37k9q4P6krUfeGp/kAAAACIEwBAAAEkO5h6sFkF4AGcX9SF/cmtXF/Uhv3J3Ul5N6k9ZopAACAREv3mSkAAICEIkwBAAAEkBZhyswuNLOtZrbNzG6p43hrM3u28vhqM+uThDIzVgz358dmttnMNprZcjPrnYw6M1G0e1Nt3KVm5mbGy72bUCz3x8y+X/nnZ5OZPdXUNWaqGP5eO9rMVpjZ+sq/20Ylo85MZGaPmNkeM3u3nuNmZr+pvHcbzWxw0Gs2+zBlZlmSCiRdJGmgpIlmNrDWsKsk/cXdj5U0X9Ivm7bKzBXj/VkvKc/dB0laKOlXTVtlZorx3sjM2ku6TtLqpq0ws8Vyf8ysv6SfSDrT3U+UdH1T15mJYvyz81NJz7n7qZImSLq/aavMaAskXdjA8Ysk9a/8uEbSA0Ev2OzDlKShkra5+3Z3PyDpGUnjao0ZJ+mxyq8XSjrPzKwJa8xkUe+Pu69w9/2Vm6sk9WziGjNVLH92JOl2VfwH5OumLA4x3Z+rJRW4+18kyd33NHGNmSqWe+OSOlR+3VHSJ01YX0Zz99cl/W8DQ8ZJ+p1XWCXpcDM7Ksg10yFM9ZC0o9r2zsp9dY5x9zJJn0s6skmqQyz3p7qrJP0+oRXhb6Lem8rp717u/nJTFgZJsf3ZOU7ScWb2lpmtMrOG/jeO+Inl3syW9AMz2ylpqaT/2zSlIQaN/XcpqlCgcoA4MrMfSMqTNDzZtUAysxaSfi1pSpJLQf1CqniqYoQqZnRfN7OT3P3/JbMoSJImSlrg7veY2TBJj5tZrruXJ7swxF86zEztktSr2nbPyn11jjGzkCqmXD9rkuoQy/2RmY2UdJuki939myaqLdNFuzftJeVKWmlmH0o6Q9JiFqE3mVj+7OyUtNjdD7r7B5LeU0W4QmLFcm+ukvScJLn725LaqOJNdpF8Mf271BjpEKYKJfU3s75m1koVC/0W1xqzWNLkyq//SdJ/O91Km0rU+2Nmp0oKqyJIseaj6TR4b9z9c3fv7O593L2PKtazXezuRckpN+PE8nfbS6qYlZKZdVbF037bm7DGTBXLvflY0nmSZGYDVBGmSpu0StRnsaQfVr6q7wxJn7t7SZATNvun+dy9zMymS3pFUpakR9x9k5nNlVTk7osl/VYVU6zbVLEobULyKs4sMd6fuyW1k/R85esCPnb3i5NWdIaI8d4gSWK8P69I+gcz2ywpIulGd2fWPcFivDc3SHrIzP5VFYvRp/Cf+KZhZk+r4j8ZnSvXrM2S1FKS3P0/VLGGbZSkbZL2S/rnwNfk3gIAABy6dHiaDwAAIGkIUwAAAAEQpgAAAAIgTAEAAARAmAIAAAiAMAUAABAAYQoAACCA/w/lT+sHrQDGdAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see from the print commands in the for loop after epoch=169 the loss of our model is always either \n",
        "\n",
        "Loss : 0.0025885067880153656 or Loss : 0.008932482451200485\n",
        "\n",
        "It means that after that number of iterations the model is quite good and no more improvement is able to be done.\n",
        "\n",
        "The parameters as we can clearly check is:\n",
        "\n",
        "weights = tensor([0.6951]) and\n",
        "\n",
        "bias = tensor([0.2993])"
      ],
      "metadata": {
        "id": "5zffpojJj8qe"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bh5rVFeAj9ja"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}